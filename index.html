<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Hao Sun - Research Page</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Sidebar -->
			<section id="sidebar">
				<div class="inner">
					<nav>
						<ul>
							<li><a href="#intro">Who I am</a></li>
							<li><a href="#research">Research</a></li>
							<li><a href="#publication">Publications</a></li>
							<li><a href="#engineering">Engineering</a></li>
							<li><a href="#contact">Contact me</a></li>
						</ul>
					</nav>
				</div>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">
					<section id="intro" class="wrapper style1 fullscreen fade-up">
						<div class="inner">
							<h1>Hao Sun</h1>
							<p>I am Hao Sun, receiving the Ph.D from Zhejiang University in China majoring in AI. Now I am a researcher in Ritsumeikan University, Japan. My research interests include multimodal learning, large models, reinforcement learning, sentiment analysis, and so on. I am extremely passionate with emerging technologies about AGI and correlated technologies.</p>
							<p>I have published several research papers in journals like Information Fusion and IEEE Transactions on Affective Computing. For more detailed research contents, please refer to my <a href="https://scholar.google.com/citations?user=0523RhEAAAAJ">Google Scholar page</a> or <a href="https://orcid.org/0000-0001-8094-1991">ORCID page</a>.</p>
							<ul class="actions">
								<li><a href="#one" class="button scrolly">Learn more</a></li>
							</ul>
						</div>
					</section>
					
					<section id="research" class="wrapper style3 fade-up">
						<div class="inner">
							<h2>Academic Research</h2>
							<p>My current research focuses on AGI, multimodal learning, large-scale models, and reinforcement learning. Previously, I explored automatic sentiment analysis, integrating linguistic, acoustic, and visual modalities. I am also passionate about translating advanced technologies into real-world applications to maximize their impact and create value.</p>
							
							<div class="features">
								<section>
									<span class="icon solid major fa-code"></span>
									<h3>AGI</h3>
									<p>Investigating methods to enable computers to think, reason, and act like humans, with a long-term goal of achieving human-level intelligence across diverse tasks.</p>
								</section>
								<section>
									<span class="icon solid major fa-gem"></span>
									<h3>Multimodal Learning</h3>
									<p>Developing algorithms that seamlessly integrate data from multiple modalities to enhance understanding and prediction capabilities in complex environments.</p>
								</section>
								<section>
									<span class="icon solid major fa-link"></span>
									<h3>Large-Scale Models</h3>
									<p>Exploring the design, training, and application of large-scale neural networks, focusing on scalability, efficiency, and real-world deployment.</p>
								</section>
								<section>
									<span class="icon solid major fa-desktop"></span>
									<h3>Sentiment Analysis</h3>
									<p>Conducted in-depth studies on understanding emotions and sentiments by analyzing multiple modalities, enabling machines to interpret human feelings more effectively.</p>
								</section>
								<!-- <section>
									<span class="icon solid major fa-gem"></span>
									<h3>Grounding Technologies into Applications</h3>
									<p>Bridging the gap between theoretical research and practical use by applying cutting-edge technologies to solve real-world challenges in fields such as healthcare, education, and industry..</p>
								</section> -->
							</div>
							<!-- <ul>
								<li><b>AGI (Artificial General Intelligence):</b> Investigating methods to enable computers to think, reason, and act like humans, with a long-term goal of achieving human-level intelligence across diverse tasks.</li>
								<li><b>Multimodal Learning:</b> Developing algorithms that seamlessly integrate data from multiple modalities—such as text, audio, and vision—to enhance understanding and prediction capabilities in complex environments.</li>
								<li><b>Large-Scale Models:</b> Exploring the design, training, and application of large-scale neural networks, focusing on scalability, efficiency, and real-world deployment.</li>
								<li><b>Reinforcement Learning:</b> Studying decision-making systems that learn optimal policies through interactions with dynamic environments, with applications in robotics, gaming, and autonomous systems.</li>
								<li><b>Sentiment Analysis:</b> Conducted in-depth studies on understanding emotions and sentiments by analyzing linguistic, acoustic, and visual cues, enabling machines to interpret human feelings more effectively.</li>
								<li><b>Grounding Technologies into Applications:</b> Bridging the gap between theoretical research and practical use by applying cutting-edge technologies to solve real-world challenges in fields such as healthcare, education, and industry.</li>
							</ul> -->
						</div>
					</section>

					<section id="publication" class="wrapper style2 spotlights">
						<div class="inner">
							<h2>Recent Publications</h2>
							<p>Below are my recent published academic papers, which covers areas such as multimodal learning, large models, and sentiment analysis. For more research papers or areas, please refer to my <a href="https://scholar.google.com/citations?user=0523RhEAAAAJ">Google Scholar page</a>. </p>
							<ul>
								<li>Sun Hao, Niu Ziwei, Wang Hongyi, et al. Multimodal Sentiment Analysis with Mutual Information-based Disentangled Representation Learning. IEEE Transactions on Affective Computing, Early Access, 2025. (Impact factor: 13.9).</li>
								<li>Sun Hao, Liu Jiaqing, Chen Yen-Wei, et al. Modality-invariant temporal representation learning for multimodal sentiment classification. Information Fusion, 91, pp 504-514, 2023. (Impact factor: 18.1)</li>
								<li>Sun Hao, Chen Yen-Wei, and Lin Lanfen. Tensorformer: A Tensor-Based Multimodal Transformer for Multimodal Sentiment Analysis and Depression Detection. IEEE Transactions on Affective Computing, 14(4), pp 2776-2786, 2022. (Impact factor: 13.9).</li>
								<li>Sun Hao, Liu Jiaqing, Chai Shurong, et al. Multi-Modal Adaptive Fusion Transformer Network for the Estimation of Depression Level. Sensors, 21(14), pp 4764, 2021. (Impact factor: 3.7)</li>
								<li>Sun Hao, Wang Hongyi, Liu Jiaqing, et al. Cubemlp: An MLP-Based Model for Multimodal Sentiment Analysis and Depression Estimation, Proceedings of the 30th ACM international conference on multimedia. pp 3722-3729. 2022. </li>
								<li>Niu Ziwei, Sun Hao, Ouyang Shuyi, et al. IRLSG: Invariant Representation Learning for Single-Domain Generalization in Medical Image Segmentation, ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, pp 5585-5589, 2024.</li>
								<li>Qiu Zhaolin, Liu Jiaqing, Sun Hao, et al. CoSTHR: A Heart Rate Estimating Network with Adaptive Color Space Transformation. IEEE Transactions on Instrumentation and Measurement, 71, pp 1-10, 2022. (Impact factor: 5.6)</li>
								<li>Niu Ziwei, Wang Hongyi, Sun Hao, et al. MCKD: Mutually Collaborative Knowledge Distillation for Federated Domain Adaptation and Generalization. ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, pp1-5, 2023</li>
								<li>Hu Jihong, Li Yinhao, Sun Hao, et al. LGA: A Language Guide Adapter for Advancing the SAM Model’s Capabilities in Medical Image Segmentation. International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer Nature Switzerland, pp 610-620, 2024.</li>
								<li>Ye Qingxin, Xie Zhenming, Sun Hao, et al. Enhancing Deep Learning-based Depression Level Estimation Based on Multi-task Learning. Proceedings of the 2024 7th International Conference on Machine Learning and Machine Intelligence. ACM, pp 59-65, 2024.</li>
								<li>and other 20+ published papers.</li>
							</ul>
						</div>
					</section>
					
					<section id="engineering" class="wrapper style3 spotlights">
						<div class="inner">
							<h2>Software Engineering</h2>
							<p>. </p>
							
						</div>
					</section>

					<section id="three" class="wrapper style1 fade-up">
						<div class="inner">
							<h2>Get in touch</h2>
							<p>Phasellus convallis elit id ullamcorper pulvinar. Duis aliquam turpis mauris, eu ultricies erat malesuada quis. Aliquam dapibus, lacus eget hendrerit bibendum, urna est aliquam sem, sit amet imperdiet est velit quis lorem.</p>
							
						</div>
					</section>

			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper style1-alt">
				<div class="inner">
					<ul class="menu">
						<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>